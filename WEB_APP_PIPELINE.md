# Face Recognition Web App - Complete Pipeline Documentation

## ğŸ“‹ Table of Contents
1. [System Architecture Overview](#system-architecture-overview)
2. [Application Startup](#application-startup)
3. [User Registration Pipeline](#user-registration-pipeline)
4. [Face Recognition Pipeline](#face-recognition-pipeline)
5. [Web Interface Routes](#web-interface-routes)
6. [Data Flow Diagrams](#data-flow-diagrams)
7. [Key Components](#key-components)

---

## ğŸ—ï¸ System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Flask Web Application (app.py)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Registration    â”‚         â”‚   Recognition    â”‚        â”‚
â”‚  â”‚   System         â”‚         â”‚    System        â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚                              â”‚                    â”‚
â”‚         â–¼                              â–¼                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚     StandaloneRegistration / StandaloneRecognition â”‚    â”‚
â”‚  â”‚  - InsightFace RetinaFace (Face Detection)    â”‚         â”‚
â”‚  â”‚  - VGGFace2 InceptionResnetV1 (Embeddings)     â”‚         â”‚
â”‚  â”‚  - masktheface (Mask Augmentation)             â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚         â”‚                              â”‚                    â”‚
â”‚         â–¼                              â–¼                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚         Embeddings Directory Structure        â”‚         â”‚
â”‚  â”‚  embeddings/                                   â”‚         â”‚
â”‚  â”‚    â”œâ”€â”€ {user_id}_{user_name}/                  â”‚         â”‚
â”‚  â”‚    â”‚   â”œâ”€â”€ centroid.npy                       â”‚         â”‚
â”‚  â”‚    â”‚   â”œâ”€â”€ metadata.json                      â”‚         â”‚
â”‚  â”‚    â”‚   â”œâ”€â”€ originals/                         â”‚         â”‚
â”‚  â”‚    â”‚   â”‚   â”œâ”€â”€ original_1.npy                 â”‚         â”‚
â”‚  â”‚    â”‚   â”‚   â”œâ”€â”€ original_2.npy                 â”‚         â”‚
â”‚  â”‚    â”‚   â”‚   â””â”€â”€ original_3.npy                 â”‚         â”‚
â”‚  â”‚    â”‚   â””â”€â”€ masked/                            â”‚         â”‚
â”‚  â”‚    â”‚       â”œâ”€â”€ img_1/                         â”‚         â”‚
â”‚  â”‚    â”‚       â”‚   â”œâ”€â”€ surgical_blue.npy          â”‚         â”‚
â”‚  â”‚    â”‚       â”‚   â”œâ”€â”€ surgical_green.npy         â”‚         â”‚
â”‚  â”‚    â”‚       â”‚   â”œâ”€â”€ cloth.npy                  â”‚         â”‚
â”‚  â”‚    â”‚       â”‚   â”œâ”€â”€ n95.npy                    â”‚         â”‚
â”‚  â”‚    â”‚       â”‚   â”œâ”€â”€ kn95.npy                   â”‚         â”‚
â”‚  â”‚    â”‚       â”‚   â””â”€â”€ gas.npy                    â”‚         â”‚
â”‚  â”‚    â”‚       â”œâ”€â”€ img_2/ (same structure)       â”‚         â”‚
â”‚  â”‚    â”‚       â””â”€â”€ img_3/ (same structure)       â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Application Startup

### Step 1: Import and Initialize
```python
1. Load Flask framework and dependencies
2. Add project root to Python path
3. Try to import src.core modules (optional)
   - If available: Use FaceRegistration & FaceRecognition
   - If not: Use StandaloneRegistration & StandaloneRecognition
```

### Step 2: Initialize AI Models
```python
StandaloneRegistration:
  â”œâ”€â”€ InsightFace RetinaFace (Face Detection)
  â”‚   â””â”€â”€ Model: "buffalo_l"
  â”‚   â””â”€â”€ Input: 640x640 images
  â”‚
  â”œâ”€â”€ VGGFace2 InceptionResnetV1 (Face Embeddings)
  â”‚   â””â”€â”€ Pretrained: 'vggface2'
  â”‚   â””â”€â”€ Output: 512-dimensional vectors
  â”‚
  â””â”€â”€ dlib (Mask Augmentation)
      â””â”€â”€ Model: shape_predictor_68_face_landmarks.dat
      â””â”€â”€ Used by masktheface library

StandaloneRecognition:
  â”œâ”€â”€ InsightFace RetinaFace (Face Detection)
  â””â”€â”€ VGGFace2 InceptionResnetV1 (Face Embeddings)
```

### Step 3: Load Existing Embeddings
```python
1. Scan embeddings/ directory
2. For each user directory:
   - Load centroid.npy (average embedding)
   - Load all original embeddings from originals/
   - Load all masked embeddings from masked/img_X/
   - Load metadata.json (user info)
3. Filter out test entries (ID="img", numeric names)
4. Store in recognition_system.known_embeddings
```

### Step 4: Start Flask Server
```python
- Host: 0.0.0.0 (all interfaces)
- Port: 5000 (default)
- Debug: True (development mode)
```

---

## ğŸ‘¤ User Registration Pipeline

### Frontend Flow (registration.html)

```
User Input
    â”‚
    â”œâ”€â”€ Name (text field)
    â”œâ”€â”€ Worker ID (text field)
    â”œâ”€â”€ Mobile Number (text field)
    â””â”€â”€ 3 Images (file inputs: image1, image2, image3)
    â”‚
    â–¼
Form Validation (JavaScript)
    â”‚
    â”œâ”€â”€ Check all fields filled
    â”œâ”€â”€ Validate image files
    â””â”€â”€ Check image quality (optional)
    â”‚
    â–¼
POST /register (AJAX)
```

### Backend Flow (/register endpoint)

```
1. Receive Form Data
   â”œâ”€â”€ Extract: name, worker_id, mobile
   â””â”€â”€ Extract: image1, image2, image3 files

2. Validation
   â”œâ”€â”€ Check required fields
   â”œâ”€â”€ Validate worker_id format (alphanumeric)
   â”œâ”€â”€ Validate mobile number format
   â”œâ”€â”€ Check all 3 images provided
   â”œâ”€â”€ Validate file sizes (< 10MB each)
   â””â”€â”€ Validate file types (images)

3. Save Images Temporarily
   â””â”€â”€ Save to temp_uploads/{worker_id}_{name}/

4. Call register_user_backend()
   â”‚
   â–¼
```

### Registration Processing (register_user_backend)

```
For each of 3 images:
â”‚
â”œâ”€â”€ Step 1: Quality Check
â”‚   â”œâ”€â”€ Read image (cv2.imread)
â”‚   â”œâ”€â”€ Calculate blur score (Laplacian variance)
â”‚   â””â”€â”€ Reject if blur < 40.0
â”‚
â”œâ”€â”€ Step 2: Face Detection
â”‚   â”œâ”€â”€ Use InsightFace RetinaFace detector
â”‚   â”œâ”€â”€ Get face bounding box
â”‚   â””â”€â”€ Extract 5-point facial landmarks
â”‚
â”œâ”€â”€ Step 3: Face Alignment
â”‚   â”œâ”€â”€ Use ArcFace 5-point alignment
â”‚   â”œâ”€â”€ Align to 112x112 pixels
â”‚   â””â”€â”€ Normalize lighting
â”‚
â”œâ”€â”€ Step 4: Extract Original Embedding
â”‚   â”œâ”€â”€ Preprocess aligned face
â”‚   â”‚   â”œâ”€â”€ Convert to float32
â”‚   â”‚   â”œâ”€â”€ Normalize to [0, 1]
â”‚   â”‚   â””â”€â”€ Apply normalization: (x - 0.5) / 0.5
â”‚   â”œâ”€â”€ Pass through VGGFace2 model
â”‚   â”œâ”€â”€ L2 normalize embedding
â”‚   â””â”€â”€ Save to originals/original_{idx}.npy
â”‚
â””â”€â”€ Step 5: Mask Augmentation (6 masks per image)
    â”‚
    For each mask type (surgical_blue, surgical_green, cloth, n95, kn95, gas):
    â”‚
    â”œâ”€â”€ Apply Mask
    â”‚   â”œâ”€â”€ Detect face with dlib
    â”‚   â”œâ”€â”€ Extract 68 facial landmarks
    â”‚   â”œâ”€â”€ Get 6 key points for mask placement
    â”‚   â”œâ”€â”€ Apply mask using masktheface
    â”‚   â””â”€â”€ Return masked image
    â”‚
    â”œâ”€â”€ Re-detect Face (on masked image)
    â”‚   â””â”€â”€ Use InsightFace RetinaFace
    â”‚
    â”œâ”€â”€ Re-align Face
    â”‚   â””â”€â”€ Use ArcFace 5-point alignment
    â”‚
    â”œâ”€â”€ Extract Masked Embedding
    â”‚   â””â”€â”€ Same process as original embedding
    â”‚
    â””â”€â”€ Save to masked/img_{idx}/{mask_type}.npy

After all images processed:
â”‚
â”œâ”€â”€ Calculate Centroid
â”‚   â”œâ”€â”€ Average all embeddings (3 originals + 18 masked = 21 total)
â”‚   â””â”€â”€ L2 normalize
â”‚   â””â”€â”€ Save to centroid.npy
â”‚
â”œâ”€â”€ Create Metadata
â”‚   â”œâ”€â”€ user_id, user_name, mobile_number
â”‚   â”œâ”€â”€ registration_date
â”‚   â”œâ”€â”€ total_embeddings count
â”‚   â”œâ”€â”€ quality_scores
â”‚   â””â”€â”€ recommended_threshold
â”‚   â””â”€â”€ Save to metadata.json
â”‚
â””â”€â”€ Return Success
    â””â”€â”€ Reload recognition system embeddings
```

### Registration Output Structure

```
embeddings/{user_id}_{user_name}/
â”œâ”€â”€ centroid.npy                    # Average of all 21 embeddings
â”œâ”€â”€ metadata.json                   # User information
â”œâ”€â”€ originals/
â”‚   â”œâ”€â”€ original_1.npy             # Embedding from image 1
â”‚   â”œâ”€â”€ original_2.npy             # Embedding from image 2
â”‚   â””â”€â”€ original_3.npy             # Embedding from image 3
â””â”€â”€ masked/
    â”œâ”€â”€ img_1/
    â”‚   â”œâ”€â”€ surgical_blue.npy      # Masked embedding 1
    â”‚   â”œâ”€â”€ surgical_green.npy     # Masked embedding 2
    â”‚   â”œâ”€â”€ cloth.npy              # Masked embedding 3
    â”‚   â”œâ”€â”€ n95.npy                # Masked embedding 4
    â”‚   â”œâ”€â”€ kn95.npy               # Masked embedding 5
    â”‚   â””â”€â”€ gas.npy                # Masked embedding 6
    â”œâ”€â”€ img_2/ (same 6 masks)
    â””â”€â”€ img_3/ (same 6 masks)

Total: 3 originals + (6 masks Ã— 3 images) = 21 embeddings per user
```

---

## ğŸ” Face Recognition Pipeline

### Frontend Flow (realtime.html or image upload)

```
Option 1: Real-time Camera
    â”‚
    â”œâ”€â”€ Access webcam (getUserMedia)
    â”œâ”€â”€ Capture frames (30 FPS)
    â””â”€â”€ Send frames to /recognize_stream

Option 2: Image Upload
    â”‚
    â”œâ”€â”€ User selects image file
    â””â”€â”€ POST /recognize with image file
```

### Backend Flow (/recognize endpoint)

```
1. Receive Image
   â”œâ”€â”€ Read image file from request
   â”œâ”€â”€ Validate file size (< 10MB)
   â”œâ”€â”€ Decode image (cv2.imdecode)
   â””â”€â”€ Validate dimensions (min 50x50)

2. Call recognize_user_backend(frame)
   â”‚
   â–¼
```

### Recognition Processing (recognize_user_backend)

```
Step 1: Face Detection
    â”œâ”€â”€ Use InsightFace RetinaFace
    â”œâ”€â”€ Detect faces in image
    â””â”€â”€ Get best face (highest confidence)

Step 2: Extract Landmarks
    â”œâ”€â”€ Get 5-point facial landmarks
    â””â”€â”€ Validate landmarks exist

Step 3: Face Alignment
    â”œâ”€â”€ Use ArcFace 5-point alignment
    â”œâ”€â”€ Align to 112x112 pixels
    â””â”€â”€ Normalize lighting

Step 4: Extract Query Embedding
    â”œâ”€â”€ Preprocess aligned face
    â”œâ”€â”€ Pass through VGGFace2 model
    â””â”€â”€ L2 normalize embedding

Step 5: Compare with Known Embeddings
    â”‚
    For each registered user:
    â”‚
    â”œâ”€â”€ Get all embeddings for user
    â”‚   â”œâ”€â”€ Original embeddings (from originals/)
    â”‚   â””â”€â”€ Masked embeddings (from masked/img_X/)
    â”‚
    â”œâ”€â”€ Calculate Similarities
    â”‚   â”œâ”€â”€ Cosine similarity: dot(query_emb, known_emb)
    â”‚   â””â”€â”€ For each embedding of this user
    â”‚
    â”œâ”€â”€ Find Maximum Similarity
    â”‚   â””â”€â”€ Take max similarity across all user's embeddings
    â”‚
    â””â”€â”€ Track Best Match
        â”œâ”€â”€ Store user with highest similarity
        â””â”€â”€ Store similarity score

Step 6: Decision Making
    â”‚
    â”œâ”€â”€ Threshold Check
    â”‚   â”œâ”€â”€ Default threshold: 0.65
    â”‚   â”œâ”€â”€ If best_score >= threshold:
    â”‚   â”‚   â””â”€â”€ Return: user_name, "Present", similarity
    â”‚   â””â”€â”€ Else:
    â”‚       â””â”€â”€ Return: None, "Not in Database", similarity
    â”‚
    â””â”€â”€ Return Result
        â”œâ”€â”€ Display name
        â”œâ”€â”€ Status (Present/Not in Database)
        â”œâ”€â”€ Time stamp
        â”œâ”€â”€ Confidence score
        â””â”€â”€ Bounding box (for visualization)
```

### Recognition Response

```json
{
  "success": true,
  "message": "Recognized with similarity 0.85",
  "name": "John Doe",
  "status": "Present",
  "time": "14:30:25",
  "bbox": [x, y, width, height]
}
```

---

## ğŸŒ Web Interface Routes

### Main Routes

| Route | Method | Purpose | Template |
|-------|--------|---------|----------|
| `/` | GET | Home/Dashboard | `index.html` |
| `/registration` | GET | Registration Form | `registration.html` |
| `/realtime` | GET | Real-time Recognition | `realtime.html` |
| `/user_access` | GET | User Management | `user_access.html` |
| `/expert_recognition` | GET | Expert Recognition | `expert_recognition.html` |

### API Endpoints

| Endpoint | Method | Purpose | Input | Output |
|----------|--------|---------|-------|--------|
| `/register` | POST | Register new user | Form data + 3 images | Success/Error |
| `/recognize` | POST | Recognize face | Image file | Name, Status, Time |
| `/recognize_stream` | GET | Real-time stream | Camera frames | Video stream |
| `/detect_face` | POST | Face detection only | Image file | Bounding box |
| `/check_photo` | POST | Photo quality check | Image file | Quality score |
| `/registered_users` | GET | Get user list | None | User list JSON |
| `/user_stats` | GET | Get statistics | None | Counts JSON |
| `/log_access` | POST | Log access attempt | JSON data | Success/Error |
| `/delete_user` | POST | Delete user | User ID | Success/Error |

---

## ğŸ“Š Data Flow Diagrams

### Registration Flow

```
User Browser
    â”‚
    â”‚ 1. Fill Form + Upload 3 Images
    â–¼
Flask Server (/register)
    â”‚
    â”‚ 2. Validate & Save Images
    â–¼
register_user_backend()
    â”‚
    â”‚ 3. Process Each Image
    â–¼
StandaloneRegistration
    â”‚
    â”œâ”€â”€ 4a. Detect Face (InsightFace)
    â”œâ”€â”€ 4b. Align Face (ArcFace)
    â”œâ”€â”€ 4c. Extract Embedding (VGGFace2)
    â”œâ”€â”€ 4d. Apply 6 Masks (masktheface)
    â””â”€â”€ 4e. Extract Masked Embeddings
    â”‚
    â”‚ 5. Calculate Centroid
    â–¼
Save to embeddings/{user_id}_{user_name}/
    â”‚
    â”‚ 6. Return Success
    â–¼
Browser (Display Success Message)
```

### Recognition Flow

```
User Browser
    â”‚
    â”‚ 1. Upload Image or Camera Frame
    â–¼
Flask Server (/recognize)
    â”‚
    â”‚ 2. Decode Image
    â–¼
recognize_user_backend()
    â”‚
    â”‚ 3. Detect & Align Face
    â–¼
StandaloneRecognition
    â”‚
    â”œâ”€â”€ 4a. Detect Face (InsightFace)
    â”œâ”€â”€ 4b. Align Face (ArcFace)
    â””â”€â”€ 4c. Extract Query Embedding (VGGFace2)
    â”‚
    â”‚ 5. Compare with Known Embeddings
    â–¼
For each user:
    â”œâ”€â”€ Load all embeddings (originals + masked)
    â”œâ”€â”€ Calculate cosine similarities
    â””â”€â”€ Find maximum similarity
    â”‚
    â”‚ 6. Decision (threshold check)
    â–¼
Return Result (Name, Status, Confidence)
    â”‚
    â”‚ 7. Display Result
    â–¼
Browser (Show Recognition Result)
```

---

## ğŸ”§ Key Components

### 1. StandaloneRegistration Class

**Purpose**: Register new users with mask augmentation

**Key Methods**:
- `__init__()`: Initialize AI models
- `_align_face()`: Align face using 5-point landmarks
- `_extract_embedding()`: Extract face embedding
- `_apply_mask()`: Apply mask using masktheface
- `register_user()`: Main registration method

**Models Used**:
- InsightFace RetinaFace (detection)
- VGGFace2 InceptionResnetV1 (embeddings)
- dlib + masktheface (mask augmentation)

### 2. StandaloneRecognition Class

**Purpose**: Recognize registered users

**Key Methods**:
- `__init__()`: Initialize models and load embeddings
- `_load_embeddings()`: Load all user embeddings
- `_align_face()`: Align face using 5-point landmarks
- `_extract_embedding()`: Extract face embedding
- `recognize_image()`: Main recognition method

**Models Used**:
- InsightFace RetinaFace (detection)
- VGGFace2 InceptionResnetV1 (embeddings)

### 3. Embedding Structure

**Why 21 embeddings per user?**
- 3 original images â†’ 3 original embeddings
- Each image gets 6 mask types â†’ 6 masked embeddings per image
- Total: 3 + (6 Ã— 3) = 21 embeddings

**Benefits**:
- Better recognition accuracy
- Handles mask-wearing scenarios
- More robust to variations

### 4. Similarity Calculation

**Method**: Cosine Similarity
```
similarity = dot(query_embedding, known_embedding)
           = |query| Ã— |known| Ã— cos(Î¸)

Since embeddings are L2-normalized:
similarity = cos(Î¸)  (ranges from -1 to 1)

For face recognition:
- similarity > 0.65: Likely match
- similarity > 0.70: Good match
- similarity > 0.80: Very confident match
```

**Matching Strategy**:
- Compare query embedding against ALL embeddings of each user
- Take maximum similarity across all embeddings
- This handles variations (masks, lighting, angles)

---

## ğŸ“ Summary

### Registration Process
1. User uploads 3 images
2. System detects and aligns faces
3. Extracts 3 original embeddings
4. Applies 6 mask types to each image
5. Extracts 18 masked embeddings
6. Calculates centroid (average of all 21)
7. Saves to embeddings directory

### Recognition Process
1. User provides image (upload or camera)
2. System detects and aligns face
3. Extracts query embedding
4. Compares with all known embeddings
5. Finds best match (maximum similarity)
6. Checks against threshold (0.65)
7. Returns recognition result

### Key Features
- âœ… Mask augmentation for robust recognition
- âœ… Multiple embeddings per user (21 total)
- âœ… Real-time camera recognition
- âœ… Image upload recognition
- âœ… User management interface
- âœ… Access logging
- âœ… Statistics dashboard

---

## ğŸ”„ Complete Request-Response Cycle

### Registration Example

```
1. User visits /registration
2. Fills form: Name="John", ID="123", Mobile="1234567890"
3. Uploads 3 images
4. JavaScript validates and sends POST /register
5. Server processes images (21 embeddings created)
6. Saves to embeddings/123_John/
7. Returns JSON: {"success": true, "message": "..."}
8. Browser shows success message
```

### Recognition Example

```
1. User visits /realtime or uploads image
2. Image sent to POST /recognize
3. Server detects face, extracts embedding
4. Compares with all known embeddings
5. Finds best match: "John" with similarity 0.85
6. Returns JSON: {"name": "John", "status": "Present", ...}
7. Browser displays recognition result
8. Access logged to user_access_log.csv
```

---

This pipeline ensures robust face recognition with mask augmentation, handling real-world scenarios where users may wear masks.

